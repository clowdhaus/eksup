---
source: eksup/tests/e2e.rs
expression: output
---
# EKS Cluster Upgrade

|                            |                           Value                           |
| :------------------------- | :-------------------------------------------------------: |
| Amazon EKS cluster         |                 `test-cluster`                      |
| Current version            |                 `v1.30`                  |
| Target version             |                  `v1.31`                  |
| EKS Managed nodegroup(s)  |  ‚ûñ   |
| Self-Managed nodegroup(s) |  ‚ûñ  |
| Fargate profile(s)         |      ‚ûñ      |

## Table of Contents

- [Upgrade the Control Plane](#upgrade-the-control-plane)
    - [Control Plane Pre-Upgrade](#control-plane-pre-upgrade)
    - [Control Plane Upgrade](#control-plane-upgrade)
- [Upgrade EKS Addons](#upgrade-eks-addons)
    - [Addon Pre-Upgrade](#addon-pre-upgrade)
    - [Addon Upgrade](#addon-upgrade)
- [Upgrade the Data Plane](#upgrade-the-data-plane)
- [Post-Upgrade](#post-upgrade)
- [References](#references)


## Upgrade the Control Plane

### Control Plane Pre-Upgrade

1. Review the following resources for affected changes in the next version of Kubernetes:

    - ‚ÑπÔ∏è [Kubernetes `1.31` release announcement](https://kubernetes.io/blog/2024/08/13/kubernetes-v1-31-release/)
    - ‚ÑπÔ∏è [EKS `1.31` release notes](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-1.31)

2. Per the [Kubernetes version skew policy](https://kubernetes.io/releases/version-skew-policy/#supported-version-skew), the `kubelet` version must not be newer than `kube-apiserver`, and may be up to two minor versions older. It is recommended that the nodes in the data plane are aligned with the same minor version as the control plane before upgrading.

    <details>
    <summary>üìå CLI Example</summary>

    Ensure you have updated your `kubeconfig` locally before executing the following commands:

    ```sh
    aws eks update-kubeconfig --region us-east-1  --name test-cluster
    ```

    Control plane Kubernetes version:

    ```sh
    kubectl version --short

    # Output (truncated)
    Server Version: v1.23.14-eks-ffeb93d
    ```

    Node(s) Kubernetes version(s):

    ```sh
    kubectl get nodes

    # Output
    NAME                                  STATUS   ROLES    AGE   VERSION
    fargate-ip-10-0-14-253.ec2.internal   Ready    <none>   9h    v1.23.14-eks-a1bebd3 ‚úÖ # Ready to upgrade
    fargate-ip-10-0-7-182.ec2.internal    Ready    <none>   9h    v1.23.14-eks-a1bebd3 ‚úÖ # Ready to upgrade
    ip-10-0-14-102.ec2.internal           Ready    <none>   9h    v1.22.15-eks-fb459a0 ‚ö†Ô∏è # Recommended to upgrade first
    ip-10-0-27-61.ec2.internal            Ready    <none>   9h    v1.22.15-eks-fb459a0 ‚ö†Ô∏è # Recommended to upgrade first
    ip-10-0-41-36.ec2.internal            Ready    <none>   9h    v1.21.14-eks-fb459a0 ‚ùå # Requires upgrade first
    ```
    </details>

    #### Check [[K8S001]](https://clowdhaus.github.io/eksup/info/checks/#k8s001)
	‚úÖ - No reported findings regarding version skew between the control plane and nodes

3. Verify that there are at least 5 free IPs in the VPC subnets used by the control plane. Amazon EKS creates new elastic network interfaces (ENIs) in any of the subnets specified for the control plane. If there are not enough available IPs, then the upgrade will fail (your control plane will stay on the prior version).

    <details>
    <summary>üìå CLI Example</summary>

    ```sh
    aws ec2 describe-subnets --region us-east-1 --subnet-ids \
        $(aws eks describe-cluster --region us-east-1 --name test-cluster \
      --query 'cluster.resourcesVpcConfig.subnetIds' --output text) \
      --query 'Subnets[*].AvailableIpAddressCount'
    ```

    </details>

    #### Check [[EKS001]](https://clowdhaus.github.io/eksup/info/checks/#eks001)
	‚úÖ - There is sufficient IP space in the subnets provided

4. Ensure the cluster is free of any health issues as reported by Amazon EKS. If there are any issues, resolution of those issues is required before upgrading the cluster. Note - resolution in some cases may require creating a new cluster. For example, if the cluster primary security group was deleted, at this time, the only course of remediation is to create a new cluster and migrate any workloads over to that cluster (treated as a blue/green cluster upgrade).

    <details>
    <summary>üìå CLI Example</summary>

    ```sh
    aws eks describe-cluster --region us-east-1 --name test-cluster \
        --query 'cluster.health'
    ```

    </details>

    #### Check [[EKS002]](https://clowdhaus.github.io/eksup/info/checks/#eks002)
	‚úÖ - There are no reported health issues on the cluster control plane

5. Ensure the EKS addons in use are using a version that is supported by the intended target Kubernetes version. If an addon is not compatible with the intended target Kubernetes version, upgrade the addon to a version that is compatible before upgrading the cluster.

    <details>
    <summary>üìå CLI Example</summary>

    ```sh
    for ADDON in $(aws eks list-addons --cluster-name test-cluster \
        --region us-east-1 --query 'addons[*]' --output text); do
      CURRENT=$(aws eks describe-addon --cluster-name test-cluster --region us-east-1 \
        --addon-name ${ADDON} --query 'addon.addonVersion' --output text)
      LATEST=$(aws eks describe-addon-versions --region us-east-1 --addon-name ${ADDON} \
        --kubernetes-version 1.31 --query 'addons[0].addonVersions[0].addonVersion' --output text)
      LIST=$(aws eks describe-addon-versions --region us-east-1 --addon-name ${ADDON} \
        --kubernetes-version 1.31 --query 'addons[0].addonVersions[*].addonVersion')

      echo "${ADDON} current version: ${CURRENT}"
      echo "${ADDON} next latest version: ${LATEST}"
      echo "${ADDON} next available versions: ${LIST}"
    done
    ```

    </details>

    #### Check [[EKS005]](https://clowdhaus.github.io/eksup/info/checks/#eks005)
	‚úÖ - There are no reported addon version compatibility issues.

5. Check Kubernetes API versions currently in use and ensure any versions that are removed in the next Kubernetes release are updated prior to upgrading the cluster. There are several open source tools that can help you identify deprecated API versions in your Kubernetes manifests. The following open source projects support scanning both your cluster as well as manifest files to identify deprecated and/or removed API versions:

    - https://github.com/FairwindsOps/pluto
    - https://github.com/doitintl/kube-no-trouble

### Control Plane Upgrade

‚ÑπÔ∏è [Updating an Amazon EKS cluster Kubernetes version](https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html)

When upgrading the control plane, Amazon EKS performs standard infrastructure and readiness health checks for network traffic on the new control plane nodes to verify that they're working as expected. If any of these checks fail, Amazon EKS reverts the infrastructure deployment, and your cluster control plane remains on the prior Kubernetes version. Running applications aren't affected, and your cluster is never left in a non-deterministic or unrecoverable state. Amazon EKS regularly backs up all managed clusters, and mechanisms exist to recover clusters if necessary.

1. Upgrade the control plane to the next Kubernetes minor version:

    ```sh
    aws eks update-cluster-version --region us-east-1 --name test-cluster \
        --kubernetes-version 1.31
    ```

2. Wait for the control plane to finish upgrading before proceeding with any further modifications. The cluster status will change to `ACTIVE` once the upgrade is complete.

    ```sh
    aws eks describe-cluster --region us-east-1 --name test-cluster \
        --query 'cluster.status'
    ```

## Upgrade the Data Plane

### Data Plane Pre-Upgrade

1. Ensure applications and services running on the cluster are setup for high-availability to minimize and avoid disruption during the upgrade process.

    üöß TODO - fill in analysis results

    #### Check [[K8S002]](https://clowdhaus.github.io/eksup/info/checks/#k8s002)
	‚úÖ - All relevant Kubernetes workloads have at least 3 replicas specified

    #### Check [[K8S003]](https://clowdhaus.github.io/eksup/info/checks/#k8s003)
	‚úÖ - All relevant Kubernetes workloads minReadySeconds set to more than 0

    #### Check [[K8S004]](https://clowdhaus.github.io/eksup/info/checks/#k8s004)
    Not yet implemented ‚Äî check manually for missing `PodDisruptionBudgets`

    #### Check [[K8S005]](https://clowdhaus.github.io/eksup/info/checks/#k8s005)
	‚úÖ - All relevant Kubernetes workloads have either podAntiAffinity or topologySpreadConstraints set

    #### Check [[K8S006]](https://clowdhaus.github.io/eksup/info/checks/#k8s006)
	‚úÖ - All relevant Kubernetes workloads have a readiness probe configured

    #### Check [[K8S007]](https://clowdhaus.github.io/eksup/info/checks/#k8s007)
	‚úÖ - No StatefulSet workloads have a terminationGracePeriodSeconds set to more than 0

    #### Check [[K8S008]](https://clowdhaus.github.io/eksup/info/checks/#k8s008)
	‚úÖ - No relevant Kubernetes workloads are found to be utilizing the Docker socket

    #### Check [[K8S011]](https://clowdhaus.github.io/eksup/info/checks/#k8s011)
	‚úÖ - `kube-proxy` version is aligned with the node/`kubelet` versions in use

    #### Check [[K8S012]](https://clowdhaus.github.io/eksup/info/checks/#k8s012)
	‚úÖ - `kube-proxy` is not using the deprecated IPVS mode

    #### Check [[K8S013]](https://clowdhaus.github.io/eksup/info/checks/#k8s013)
	‚úÖ - No Ingress NGINX controller images detected that require migration

2. Inspect [AWS service quotas](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html) before upgrading. Accounts that are multi-tenant or already have a number of resources provisioned may be at risk of hitting service quota limits which will cause the cluster upgrade to fail, or impede the upgrade process.

3. Verify that there is sufficient IP space available to the pods running in the cluster when using custom networking. With the in-place, surge upgrade process, there will be higher IP consumption during the upgrade.

    <details>
    <summary>üìå CLI Example</summary>

    Ensure you have updated your `kubeconfig` locally before executing the following commands:

    ```sh
    aws eks update-kubeconfig --region us-east-1  --name test-cluster
    ```

    Get the number of available IPs in each subnet used by the custom networking `ENIConfig` resources:
    ```sh
    aws ec2 describe-subnets --region us-east-1 --subnet-ids \
        $(kubectl get ENIConfigs -n kube-system -o jsonpath='{.items[*].spec.subnet}') \
        --query 'Subnets[*].AvailableIpAddressCount'
    ```

    </details>

    #### Check [[AWS002]](https://clowdhaus.github.io/eksup/info/checks/#aws002)
	‚úÖ - There is sufficient IP space in the subnets provided


## Upgrade EKS Addons

### Addon Pre-Upgrade

1. Ensure the EKS addons in use are free of any health issues as reported by Amazon EKS. If there are any issues, resolution of those issues is required before upgrading the cluster.

    <details>
    <summary>üìå CLI Example</summary>

    ```sh
    aws eks describe-addon --region us-east-1 --cluster-name test-cluster \
        --addon-name <ADDON_NAME> --query 'addon.health'
    ```

    </details>

    #### Check [[EKS004]](https://clowdhaus.github.io/eksup/info/checks/#eks004)
	‚úÖ - There are no reported addon health issues.

### Addon Upgrade

1. Upgrade the addon to an appropriate version for the upgraded Kubernetes version:

    ```sh
    aws eks update-addon --region us-east-1 --cluster-name test-cluster \
        --addon-name <ADDON_NAME> --addon-version <ADDON_VERSION>
    ```

    You may need to add `--resolve-conflicts OVERWRITE` to the command if the addon has been modified since it was deployed to ensure the addon is upgraded.

## Post Upgrade

- Update applications running on the cluster
- Update tools that interact with the cluster (kubectl, awscli, etc.)
